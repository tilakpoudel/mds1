par(mar = c(0, 0, 0, 0))  # Remove all margins
plot(clp, net)
cfg <- cluster_fast_greedy(as.undirected(net))
par(mar = c(0, 0, 0, 0))  # Remove all margins
plot(cfg, as.undirected(net))
lo <- layout_with_fr(net)
cfg <- cluster_fast_greedy(as.undirected(net))
par(mar = c(0, 0, 0, 0))  # Remove all margins
plot(cfg, as.undirected(net), layout=lo, vertex.label=NA,)
lo <- layout_with_fr(net)
cfg <- cluster_fast_greedy(as.undirected(net))
# par(mar = c(0, 0, 0, 0))  # Remove all margins
plot(cfg, as.undirected(net), layout=lo)
clp <- cluster_label_prop(net)
lo <- layout_with_fr(net)  # consistent layout
# pdf("clustered_plot.pdf", width = 8, height = 8)
par(mar = rep(0.2, 4))  # Tiny margins
# Use `plot()` from `igraph`, not from cluster object directly
plot(net, layout = lo,
vertex.color = clp$membership,
vertex.label = NA,
vertex.size = 6,
main = "Label Propagation Clusters")
# Use `plot()` from `igraph`, not from cluster object directly
plot(net, layout = lo,
# vertex.color = clp$membership,
vertex.label = NA,
# vertex.size = 6,
main = "Label Propagation Clusters")
# Use `plot()` from `igraph`, not from cluster object directly
plot(net, layout = lo,
# vertex.color = clp$membership,
vertex.label = NA,
# vertex.size = 6,
main = "Label Propagation Clusters")
# Use `plot()` from `igraph`, not from cluster object directly
plot(net, layout = lo,
# vertex.color = clp$membership,
vertex.label = NA,
# vertex.size = 6,
main = "Label Propagation Clusters")
clp <- cluster_label_prop(net)
plot(clp, net)
clp <- cluster_label_prop(net)
plot(clp, net)
cfg <- cluster_fast_greedy(as.undirected(net))
plot(cfg, as.undirected(net))
library(igraph)
g1 <- graph(edges=c(1,2, 2,3, 3,1),n=3,directed=F)
plot(g1,vertex.size=50)
class(g1)
g1
g2 <- graph(edges=c(1,2, 2,3, 3,1),n=10)
plot(g2,vertex.size=10)
g2
g3 <- graph
# Accuracy indices
# using residuals of linear model
lm1 <- lm(mpg~wt, data=mtcars)
names(lm1)
(mse <- mean(lm1$residuals ^ 2))
# saving predicted values
data <- data.frame(
pred = predict(lm1), actual=mtcars$mpg
)
head(data)
mean((data$actual - data$pred) ^2)
data(caret)
install.packages('caret')
library(caret)
R2 <- R2(data$pred, data$actual)
print(R2)
RMSE <- RMSE(data$pred, data$actual)
print(RMSE)
MAE <- MAE(data$pred, data$actual)
print(MAE)
?MAPE
# 1 Validation
data <- mtcars
#  use random seed to replicate the result
set.seed(39)
# DIvide into trainig and test data
ind <- sample(2, nrow(mtcars), replace = T, prob(0.7, 0.3))
# DIvide into trainig and test data
ind <- sample(2, nrow(mtcars), replace = T, prob= c(0.7, 0.3))
# Data partition
train.data <- data[ind = 1]
# Data partition
train.data <- data[ind = 1,]
test.data <- data[ind = 2,]
# Data partition
train.data <- data[ind == 1,]
test.data <- data[ind == 2,]
print(ind)
lm4 <- lm(mpg~wt, data = train.data)
library(dplyr)
library(caret)
predictions <- lm4 %>%
predict(test.data)
data.frame(
R2 = R2(predictions, test.data$mpg),
RMSE = RMSE(predictions, test.data$mpg),
MAE = MAE(predictions, test.data$mpg)
)
summary(lm4)
#  use random seed to replicate the result
set.seed(1234)
# DIvide into training and test data
ind <- sample(2, nrow(mtcars), replace = T, prob= c(0.7, 0.3))
print(ind)
# Data partition
train.data <- data[ind == 1,]
test.data <- data[ind == 2,]
# Model fitting
lm4 <- lm(mpg~wt, data = train.data)
library(dplyr)
library(caret)
predictions <- lm4 %>%
predict(test.data)
data.frame(
R2 = R2(predictions, test.data$mpg),
RMSE = RMSE(predictions, test.data$mpg),
MAE = MAE(predictions, test.data$mpg)
)
summary(lm4)
summary(lm4)
library(dplyr)
library(caret)
predictions <- lm4 %>%
predict(test.data)
data.frame(
R2 = R2(predictions, test.data$mpg),
RMSE = RMSE(predictions, test.data$mpg),
MAE = MAE(predictions, test.data$mpg)
)
sqrt(9.526359)
# Leave one out Cross Validation
library(caret)
# Define training control
train.control <- trainControl(method = "LOOCV")
# Train the model
model1 <- train(
mpg~wt,
data = train.data,
method="lm",
trControl=train.control
)
summary(model1)
# test on test data
prediction1 <- model1 %>%
predict(test.data)
data.frame(
R2 <- R2(predictions1, test.data$mpg),
RMSE = RMSE(prediction1, test.data$mpg),
MAE = MAE(presidiction1, test.data$mpg)
)
data.frame(
R2 <- R2(predictions1, test.data$mpg),
RMSE = RMSE(prediction1, test.data$mpg),
MAE = MAE(prediction1, test.data$mpg)
)
data.frame(
R2 <- R2(prediction1, test.data$mpg),
RMSE = RMSE(prediction1, test.data$mpg),
MAE = MAE(prediction1, test.data$mpg)
)
data.frame(
R2 = R2(prediction1, test.data$mpg),
RMSE = RMSE(prediction1, test.data$mpg),
MAE = MAE(prediction1, test.data$mpg)
)
# MULTIPLE LINEAR REGRESSION MODEL
# more than 1 independent variable
mlr <- lm(mpg~., data = mtcars)
summary(mlr)
str(mtcars)
library(car)
vif(mlr)
install.packages(car)
install.packages('car')
install.packages('car')
#  disp has vif >10 so drop it
mlr1 <- lm(
mpg~cyl+hp+drat+wt+qsec+vs+am+gear+carb,
data = mtcars
)
summary(lmr1)
summary(mlr1)
vif(mlr1)
library(car)
vif(mlr)
#  disp has vif >10 so drop it
mlr1 <- lm(
mpg~cyl+hp+drat+wt+qsec+vs+am+gear+carb,
data = mtcars
)
summary(mlr1)
vif(mlr1)
#  disp has vif >10 so drop it
mlr2 <- lm(
mpg~hp+drat+wt+qsec+vs+am+gear+carb,
data = mtcars
)
summary(mlr2)
vif(mlr2)
vif(mlr1)
#  cyl has vif >10 so drop it
mlr2 <- lm(
mpg~hp+drat+wt+qsec+vs+am+gear+carb,
data = mtcars
)
summary(mlr2)
vif(mlr2)
#  gear has vif >10 so drop it
mlr3 <- lm(
mpg~hp+drat+wt+qsec+vs+am+carb,
data = mtcars
)
summary(mlr3)
vif(mlr3)
boston = MASS::Boston
str(boston)
# Load the data
boston = MASS::Boston
str(boston)
# Data partition
set.seed(123)
ind <-sample(
2,
nrow(boston),
replace = T,
prob = c(0.8, 0.2),
train.data = boston[ind == 1,],
test.data = boston[ind == 2,]
)
ind <-sample(
2,
nrow(boston),
replace = T,
prob = c(0.8, 0.2)
)
train.data = boston[ind == 1,],
train.data = boston[ind == 1,]
test.data = boston[ind == 2,]
# Training data scaling (must for KNN)
train_x = train.data[, -14]
train_x = scale(train_x)[,]
train_y = train.data[, 14]
# Test validaton data scaling
test_x = test.data[, -14]
test_x = scale(test.data[, -14])[,]
test_y = test.data[, 14]
# Load the data
library(caret)
# KNN regression, struture, predition
knnmodel = knnreg(train_x, trainy)
str(knnmodel)
# KNN regression, struture, predition
knnmodel = knnreg(train_x, trainy)
# KNN regression, struture, predition
knnmodel = knnreg(train_x, train_y)
str(knnmodel)
# Prediction
pred_y = predict(knnmodel, data.frame(test_x))
summary(knnmodel)
# Prediction
pred_y = predict(knnmodel, data.frame(test_x))
# print accuracy indices
print(data.frame(test_y, pred_y))
mse = mean((test_y - pred_y) ^ 2)
print(mse)
mae = caret::MAE(test_y, pred_y)
print(mae)
rmse = caret::RMSE(test_y, pred_y)
print(rmse)
cat("MSE:", mse, "MAE:", mae, "RMSE:", rmse, "\n")
plot(x, test_y, col = "red", type="l", lwd=2,
xlab = "Index", ylab = "Value",
main = "KNN Regression")
plott(x, test_y, col = "blue", type="l", lwd=2,
xlab = "Index", ylab = "Value",
main = "KNN Regression")
plot(x, test_y, col = "blue", type="l", lwd=2,
xlab = "Index", ylab = "Value",
main = "KNN Regression")
lines(x, pred_y, col = "red", lwd=2)
legend("topright", legend = c("Actual", "Predicted"),
col = c("blue", "red"), lwd = 2)
# Plot
plot(
test_y,
pred_y,
col = "blue",
pch = 19,
xlab = "Index",
ylab = "Value",
main = "KNN Regression"
)
abline(0, 1, col = "red", lwd = 2)
install.packages('party')
install.packages('ipred')
install.packages('randomForest')
#
library(readr)
getwd()
setwd("~/projects/tilak/mds1/R-programming")
getwd()
cardiotocographics <- read_csv("data/Cardiotocographic.csv")
data <- cardiotocographics
str(data)
table(data)
data$NSPF <- factor(data$NSP)
str(data$NSPF)
#  Data partition
set.seed(1234)
ind <- sample(2, nrow(data), replace=T, prob=c(0.8, 0.2))
train <- data[ind==1, ]
train <- data[ind==1,]
test <-data[ind==2,]
#
library(readr)
getwd()
setwd("~/projects/tilak/mds1/R-programming")
getwd()
cardiotocographics <- read_csv("data/Cardiotocographic.csv")
data <- cardiotocographics
str(data)
table(data)
data$NSPF <- factor(data$NSP)
str(data$NSPF)
#  Data partition
set.seed(1234)
ind <- sample(2, nrow(data), replace=T, prob=c(0.8, 0.2))
train <- data[ind==1,]
test <-data[ind==2,]
# Party package
libray("party")
# Party package
install.packages("party")
libray("party")
# Fit the decision treel model
tree <- ctree(NSPF~LB+AC+FM, data=train)
tree
plot(tree)
# Party package
# install.packages("party")
libray("party")
# Party package
install.packages("party")
libray("party")
install.packages("party")
library(party)
# Fit the decision treel model
tree <- ctree(NSPF~LB+AC+FM, data=train)
tree
plot(tree)
#  Prunning the tree with 99% confidence interavel and split at 500 samples
tree1 <- ctree(
NSFP ~ LB+AC+FM,
data = train,
controls=ctree_control(mincriterion = 0.99, minsplit = 500)
)
#  Prunning the tree with 99% confidence interavel and split at 500 samples
tree1 <- ctree(
NSPF ~ LB+AC+FM,
data = train,
controls=ctree_control(mincriterion = 0.99, minsplit = 500)
)
plot(tree1)
tree1
#  Now lets predict
predict(tree, type="prob")
predict(tree1, type="prob")
# Predict the cateogory for each case in test data
predict(tree, test)
predict(tree1, test)
#  Now lets predict
predict(tree, type="prob")
cler
#  Now lets predict
predict(tree, type="prob")
# Create confusion matrix
(tab <- table(predict(tree), train$NSPF))
#  Accuracy
accuracy <- sum(diag(tab))/sum(tab)
accuracy
# Misclassification error
mce <- 1 -accuracy
mce
#  Now lets predict
predict(tree, type="prob")
predict(tree1, type="prob")
#  Accuracy
accuracy <- sum(diag(tab))/sum(tab)
accuracy
# Misclassification error
mce <- 1 -accuracy
mce
# Prediction on test data
pred.test <- predict(tree, newdata= test)
# Confusion matrix of test data
(tab1<- table(pred.test, test$NSPF))
#  Accuracy
accuracy1 <- sum(diag(tab1))/ sum(tab1)
accuracy1
#  Misclassification error
mce1 <- 1 - accuracy1
mce1
# - Baggin : Bootstrap aggeration
# Use ipred package for bagging
library(ipred)
MBTree <- bagging(NSPF~LB+AC+FM, data=train, coob=T)
print(MBTree)
#  Prediction
MBPredict1 <- predict(MBTree, test)
MBPredict1
library(caret)
# Confusion matrix
confusionMatrix(MBPredict1, test$NSPF)
# 2. RANDOM FOREST
library(randomForest)
set.seed(222)
# Fit random forest model
rfm <- randomForest(NSPF~LB+AC+FM, data= train)
print(rfm)
#  use caret to predict
libray(caret)
#  use caret to predict
library(caret)
p1 <- predict(rfm, train)
head(p1)
#  see original valies
head(train$NSPF)
#  Confusion matrix
confusionMatrix(p1, train$NSPF)
mce <- 1- 0.8661
mce
#  see on test data
confusionMatrix(p1, test$NSPF)
#  see on test data
p2 <- predict(p1, test)
#  see on test data
p2 <- predict(rfm, test)
confusionMatrix(p2, test$NSPF)
plot(rmf)
plot(rfm)
#  TUning the random forest model
train <- as.data.frame(train)
# fined tuned random forest and chec OOB error
# Improved  rfm model
rfm1 <- randomForest(
NSP~LB+AC+FM,
data= train,
ntree = 300,
mtry = 4,
importance = TRUE,
proximity = TRUE
)
print(rfm1)
# predict on training data
p1 <- predict(rfm1, train)
head(p1)
# 3. BOOSTING
# Generalized Boositing refression model
library(caret)
mod.gbm <- train(NSP~., data= train, method="gbm", verbose=F)
mod.gbm <- train(NSP~., data= train, method="gbm", verbose=F)
print(mod.gbm)
# Unsupervised learning
# Priciplal component analysis
head(USArrests)
# USArrests is a data frame with 50 observations on 4 variables.
str(USArrests))
# USArrests is a data frame with 50 observations on 4 variables.
str(USArrests)
data <- USArrests
data
library(dplyr)
USArrests.1 <- USArrests[,-3] %>>
USArrests.1 <- USArrests[,-3] %>%
scale
# Fitting PCA in the new data
pca.1 <- prcomp(USArrests.1)
summary(pca.1)
install.packages('psych')
#  We can use psych package as well
library(psych)
fa.1 <- psych::principal(USArrests.1, nfactors = 3, rotate = "varimax")
summary(fa.2)
summary(fa.1)
fa.1 <- psych::principal(USArrests.1, nfactors = 3, rotate = "none")
summary(fa.1)
# Multi dimensional Scaling (mDS)
USArrests.1 <- scale(USArrests[,-3])
#  classical MDS with kruskal stress
# we first need distance
#  distance calculationm
state.disimilarity <- dist(USArrests.1)
# MDS fit
mds.1 <- cmdscale(state.disimilarity)
summary(mds.1)
# MDS plot
plot(mds.1, pch=19)
abline(h=0, v=0)
#  We can tryuisng sammon's stress
library(MASS)
mds2 <- sammon(state.disimilarity, trace = FALSE)
plot(mds2$points, pch=19)
ablne(h=0, v=0, lty=2)
abline(h=0, v=0, lty=2)
text(mds2$points, labels = rownames(USArrests.1), cex=0.7, pos=4)
mds2
