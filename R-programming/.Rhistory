cat("Testing Set Size:", nrow(test), "\n")
# Load the iris data set from a CSV file
iris <- read.csv("../data/iris.csv")
# Set a seed for reproducibility (ensures the same random split every time)
set.seed(123)
# Create a logical vector for 70:30 train-test split
# TRUE (70% of rows) → Train set, FALSE (30% of rows) → Test set
tt.sample <- sample(c(TRUE, FALSE), nrow(iris), replace = TRUE, prob = c(0.7, 0.3))
# Subset iris data set into training (70%) and testing (30%) sets
train <- iris[tt.sample, ]  # Training set
test <- iris[!tt.sample, ]  # Testing set
# Print data set sizes
cat("Training Set Size:", nrow(train), "\n")
cat("Testing Set Size:", nrow(test), "\n")
# define function
roll <- function() {
die <- 1:6
# size = 2 => it means 2 dices are rolled
dice <- sample(die, size = 2, replace=TRUE)
# get the sum of result of 2 dice
sum(dice)
}
# call function
roll()
roll()
roll()
# with parameter
roll2 <- function(die = 1:6) {
# size = 2 => it means 2 dices are rolled
dice <- sample(die, size = 2, replace=TRUE)
# get the sum of result of 2 dice
sum(dice)
}
roll2()
# with parameter
roll3 <- function(dice) {
# size = 2 => it means 2 dices are rolled
dice <- sample(dice, size = 2, replace=TRUE)
# get the sum of result of 2 dice
sum(dice)
}
roll3(dice = 1:6)
roll3(dice = 1:12)
roll3(dice = 1:24)
best_practice <- c(“Let”, “the”, “computer”, “do”, “the”, “work”)
best_practice <- c("Let", "the", "computer", "do", "the", "work")
print_words <- function(sentence) {
print(sentence[1])
print(sentence[2])
print(sentence[3])
print(sentence[4])
print(sentence[5])
print(sentence[6])
}
print_words(best_practice) # [1] ”Let” [1] “the” [1] “computer” [1] “do” [1] “the” [1] “work”
print_words(best_practice[-6]) # [1] ”Let” [1] “the” [1] “computer” [1] “do” [1] “the” [1] “NA”
best_practice[-6]
print_words <- function(sentence) {
print(sentence[1])
print(sentence[2])
print(sentence[3])
print(sentence[4])
print(sentence[5])
print(sentence[6])
}
print_words(best_practice) # [1] ”Let” [1] “the” [1] “computer” [1] “do” [1] “the” [1] “work”
print_words(best_practice[-6]) # [1] ”Let” [1] “the” [1] “computer” [1] “do” [1] “the” [1] “NA”
best_practice[-6]
best_practice <- c("Let", "the", "computer", "do", "the", "work")
print_words <- function(sentence) {
for (word in sentence) {
print(word)
}
}
print_words(best_practice)       # Prints all words
print_words(best_practice[-6])   # Prints first 5 words without NA
# Create a matrix
mat <- matrix(1:9, nrow = 3, byrow = TRUE)
# Apply sum function across columns (MARGIN = 2)
apply(mat, MARGIN = 2, FUN = sum)
# Output: [1] 12 15 18
# Create a matrix
mat <- matrix(1:9, nrow = 3, byrow = TRUE)
print(mat)
# Apply sum function across columns (MARGIN = 2)
apply(mat, MARGIN = 2, FUN = sum)
# Output: [1] 12 15 18
# Create a matrix
mat <- matrix(1:9, nrow = 3, byrow = TRUE)
print(mat)
# Apply sum function across columns (MARGIN = 2)
apply(mat, MARGIN = 2, FUN = sum)
# Output: [1] 12 15 18
# Apply sum function across rows (MARGIN = 1)
apply(mat, MARGIN = 1, FUN = sum)
# Output: [1] 12 15 18
# Create a data frame
df <- data.frame(a = 1:3, b = letters[1:3])
# Apply length function to each column of df
lapply(df, length)
# Output: $a [1] 3  $b [1] 3
df
# Create a data frame
df <- data.frame(a = 1:3, b = letters[1:3])
df
# Apply length function to each column of df
lapply(df, length)
# Output: $a [1] 3  $b [1] 3
# Create a data frame
df <- data.frame(a = 1:3, b = letters[1:3])
# Apply length function to each column of df
sapply(df, length)
# Output: a b
#         3 3
# Create a data frame
df <- data.frame(a = 1:3, b = letters[1:3])
# Apply length function to each column of df
sapply(df, length)
# Output: a b
#         3 3
# Create a data frame
df <- data.frame(a = 1:3, b = letters[1:3])
# Apply length function to each column of df
sapply(df, length)
# Output: a b
#         3 3
# Create a data frame
df <- data.frame(a = 1:3, b = letters[1:3])
# Apply length function to each column and specify output type
vapply(df, length, FUN.VALUE = integer(1))
# Output: a b
#         3 3
age <- 1:99
check_age <- function(age) {
if (age <= 15) {
print("Children")
} else {
if (age <= 65) {
print("Working group")
} else {
print("Senior citizen")
}
}
}
check_age(10)
check_age(52)
check_age(70)
check_age1 <- function(age) {
if (age <= 15) {
print("Children")
} else if(age > 15 && age <= 65) {
print("Working group")
} else {
print("Senior citizen")
}
}
check_age1(101)
check_age1(52)
check_age1(70)
check_age12 <- function(age) {
result <- ifelse(
age<=15, "child",
ifelse(
(age > 15 && age <= 65), "Working", "senior")
)
print(result)
}
check_age12(101)
check_age12(52)
check_age12(70)
age <- 1:99
check_age <- function(age) {
if (age <= 15) {
print("Children")
} else {
if (age <= 65) {
print("Working group")
} else {
print("Senior citizen")
}
}
}
check_age(10)
check_age(52)
check_age(70)
check_age1 <- function(age) {
if (age <= 15) {
print("Children")
} else if(age > 15 && age <= 65) {
print("Working group")
} else {
print("Senior citizen")
}
}
check_age1(101)
check_age1(52)
check_age1(70)
check_age12 <- function(age) {
result <- ifelse(
age<=15, "child",
ifelse(
(age > 15 && age <= 65), "Working", "senior")
)
print(result)
}
check_age12(101)
check_age12(52)
check_age12(70)
y <- 1:40
ifelse(y<20, "Too low", "Too high")
#It’s a logical as:
ifelse(y<20, TRUE, FALSE)
library(nycflights13)
flights
gc()
library(nycflights13)
flights
library(dplyr)
library("RSQLite")
library(DBI)
con <- dbConnect(
RSQLite::SQLite(),
":memory:"
)
dbListTables(con)
dbWriteTable(con, "mtcars", mtcars)
dbListTables(con)
dbListFields(con, "mtcars")
res <- dbSendQuery(
con,
"SELECT * FROM mtcars WHERE cyl = 4"
)
dbFetch(res)
dbClearResult(res)
dbDisconnect(con)
con <- DBI:: dbConnect(
duckdb::duckdb()
)
install.packages("duckdb")
install.packages("ggplot2")
dbWriteTable(con, "mpg", ggplot2::mpg)
con <- DBI:: dbConnect(
duckdb::duckdb()
)
con <- DBI:: dbConnect(
duckdb::duckdb()
)
library(duckdb)
library(duckdb)
install.packages("duckdb")
install.packages("duckdb")
library(duckdb)
install.packages("ggplot2")
library(duckdb)
con <- DBI::dbConnect(
duckdb::duckdb()
)
install.packages("duckdb")
install.packages("duckdb")
install.packages('tweetR')
install.packages('tm')
install.packages("tweetR")
install.packages("rtweet")
library('tm')
library('rtweet')
load("/home/tilak/Downloads/rdmTweets.RData")
library(nycflights13)
library(dplyr)
head(flights)
str(flights)
jan1 <- dplyr::filter(flights, month == 1, day == 1)
print(jan1)
(jan1 <- dplyr::filter(flights == 1, day == 1)) # save as an object
jan1 <- dplyr::filter(flights, month == 1, day == 1)
print(jan1)
(jan1 <- dplyr::filter(flights == 1, day == 1)) # save as an object
(jan1 <- dplyr::filter(flights, month== 1, day == 1)) # save as an object
library(rvest)
url = "https://data.covid19india.org/"
webPage <- read_html(url)
str(webPage)
library('rtweet')
load(file = "../data/rmdTweets.RData")
load(file = "data/rmdTweets.RData")
load(file = "../data/rmdTweets.RData")
load(file = "./data/rmdTweets.RData")
load(file = "../../data/rmdTweets.RData")
load(file = "data/rmdTweets.RData")
load(file = "../data/rmdTweets.RData")
load(file = "../data/rmdTweets.RData")
load(file = "../../data/rmdTweets.RData")
load(file = "data/rmdTweets.RData")
install.packages("wdman")
library(wdman)
chrome_driver <- chromedriver()
install.packages("wdman")
install.packages("wdman")
library(wdman)
chrome_driver <- chromedriver()
install.packages("RSelenium")
install.packages("wdman")
install.packages("netstat")
suppressWarnings({
library(RSelenium)
library(rvest)
library(netstat)
library(jsonlite)
})
port <- free_port()
rD <- rsDriver(
browser = "chrome",
port = port,
verbose = FALSE,
chromever = "latest"  # Ensures it fetches the latest ChromeDriver
)
rD <- rsDriver(
browser = "chrome",
port = port,
verbose = FALSE,
chromever = "134.0.6998.35"
)
rD <- rsDriver(
browser = "chrome",
port = port,
verbose = FALSE,
chromever = "114.0.5735.90"
)
rD <- rsDriver(
browser = "chrome",
port = port,
verbose = FALSE,
chromever = "134.0.6998.35"
)
rD <- rsDriver(browser = "firefox", verbose = FALSE)
suppressWarnings({
library(RSelenium)
library(rvest)
library(netstat)
library(jsonlite)
})
library(wdman)
rD <- rsDriver(browser = "firefox", verbose = FALSE)
library(rvest)
library(jsonlite)
# set the working directory
getwd()
setwd("~/projects/tilak/mds1/R-programming")
# web page url
url = "https://data.covid19india.org/"
webpage <- read_html(url)
# observe the structure of the web page
str(webpage)
# get the title of the page
h3_elements <- webpage %>%
html_nodes("h3") %>%
html_text()
# get all the h3 elements for table title
str(h3_elements)
# Get first h3 for first table
highestCovid19DeathTitle <- h3_elements[[1]]
highestCovid19DeathTitle
# Get the data from the table
table_nodes <- webpage %>% html_nodes("table.has-fixed-layout")
# Part1 : First table with no of death info
death_table = table_nodes[[1]]
# Extract rows and cells
rows <- death_table %>% html_nodes("tr")
data_list <- list()
# Loop through each row and extract the key-value pairs
for (row in rows) {
cells <- row %>% html_nodes("td") %>% html_text(trim = TRUE)
if (length(cells) == 2) {
# Clean up the key (convert to lowercase, replace spaces with underscores)
key <- gsub("\\s+", "_", tolower(cells[1]))
data_list[[key]] <- trimws(cells[2])
}
}
# Wrap the entire data_list inside a new key called "data"
final_data <- list(data = data_list)
# Convert list to JSON — ensure no arrays for single values
json_data <- jsonlite::toJSON(final_data, pretty = TRUE, auto_unbox = TRUE)
# Save to file
output_path <- "output/india_covid19_death_data.json"
write(json_data, file = output_path)
# Part2 : second table with number of recovered info
recovery_table = table_nodes[[2]]
# Extract the rows of the table
table <- recovery_table %>%
html_table(fill = TRUE)
table_data <- list()
# Skip the first row (header) and loop through the remaining rows
# Start from 2 to skip the header row
for (i in 2:nrow(table)) {
# Extract and clean the row data
year <- trimws(table[i, 1])  # First column: Year
daily_cases <- trimws(table[i, 2])  # Second column: Daily Cases
recovery_rate <- trimws(table[i, 3])  # Third column: Recovery Rate
# Skip rows where all values are empty
if (all(c(year, daily_cases, recovery_rate) == "")) {
next
}
# Use gsub to clean data for both fields
daily_cases <- gsub("—", "", daily_cases)  # Replace em dash with empty string
daily_cases <- gsub("[^0-9]", "", daily_cases)  # Keep only numeric characters
# Clean recovery rate: replace "—" and "%" and convert to decimal if needed
recovery_rate <- gsub("—", "", recovery_rate)  # Remove '—'
recovery_rate <- gsub("%", "", recovery_rate)  # Remove '%'
# Store the cleaned data in the list (index correctly)
table_data[[length(table_data) + 1]] <- list(  # This ensures no duplication
year = year,
number_of_cases = daily_cases,
recovery_rate = recovery_rate
)
}
# Wrap the data in a top-level 'data' key
final_data <- list(data = table_data)
# Convert the list to JSON, ensuring no arrays for single values
json_data <- toJSON(final_data, pretty = TRUE, auto_unbox = TRUE)
print(json_data)
# Define the output file path
output_path <- "output/india_covid19_recovery_data.json"
# Ensure the output folder exists
if (!dir.exists("output")) {
dir.create("output", recursive = TRUE)
}
# Save the JSON file
write(json_data, file = output_path)
library(rvest)
library(jsonlite)
# set the working directory
getwd()
setwd("~/projects/tilak/mds1/R-programming")
# web page url
url = "https://data.covid19india.org/"
webpage <- read_html(url)
# observe the structure of the web page
str(webpage)
# get the title of the page
h3_elements <- webpage %>%
html_nodes("h3") %>%
html_text()
# get all the h3 elements for table title
str(h3_elements)
# Get first h3 for first table
highestCovid19DeathTitle <- h3_elements[[1]]
highestCovid19DeathTitle
# Get the data from the table
table_nodes <- webpage %>% html_nodes("table.has-fixed-layout")
# Part1 : First table with no of death info
death_table = table_nodes[[1]]
# Extract rows and cells
rows <- death_table %>% html_nodes("tr")
data_list <- list()
# Loop through each row and extract the key-value pairs
for (row in rows) {
cells <- row %>% html_nodes("td") %>% html_text(trim = TRUE)
if (length(cells) == 2) {
# Clean up the key (convert to lowercase, replace spaces with underscores)
key <- gsub("\\s+", "_", tolower(cells[1]))
data_list[[key]] <- trimws(cells[2])
}
}
# Wrap the entire data_list inside a new key called "data"
final_data <- list(data = data_list)
# Convert list to JSON — ensure no arrays for single values
json_data <- jsonlite::toJSON(final_data, pretty = TRUE, auto_unbox = TRUE)
# Save to file
output_path <- "output/india_covid19_death_data.json"
write(json_data, file = output_path)
# Part2 : second table with number of recovered info
recovery_table = table_nodes[[2]]
# Extract the rows of the table
table <- recovery_table %>%
html_table(fill = TRUE)
table_data <- list()
# Skip the first row (header) and loop through the remaining rows
# Start from 2 to skip the header row
for (i in 2:nrow(table)) {
# Extract and clean the row data
year <- trimws(table[i, 1])  # First column: Year
daily_cases <- trimws(table[i, 2])  # Second column: Daily Cases
recovery_rate <- trimws(table[i, 3])  # Third column: Recovery Rate
# Skip rows where all values are empty
if (all(c(year, daily_cases, recovery_rate) == "")) {
next
}
# Use gsub to clean data for both fields
daily_cases <- gsub("—", "", daily_cases)  # Replace em dash with empty string
daily_cases <- gsub("[^0-9]", "", daily_cases)  # Keep only numeric characters
# Clean recovery rate: replace "—" and "%" and convert to decimal if needed
recovery_rate <- gsub("—", "", recovery_rate)  # Remove '—'
recovery_rate <- gsub("%", "", recovery_rate)  # Remove '%'
# Store the cleaned data in the list (index correctly)
table_data[[length(table_data) + 1]] <- list(  # This ensures no duplication
year = year,
number_of_cases = daily_cases,
recovery_rate = recovery_rate
)
}
# Wrap the data in a top-level 'data' key
final_data <- list(data = table_data)
# Convert the list to JSON, ensuring no arrays for single values
json_data <- toJSON(final_data, pretty = TRUE, auto_unbox = TRUE)
print(json_data)
# Define the output file path
output_path <- "output/india_covid19_recovery_data.json"
# Ensure the output folder exists
if (!dir.exists("output")) {
dir.create("output", recursive = TRUE)
}
# Save the JSON file
write(json_data, file = output_path)
